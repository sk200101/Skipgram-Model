{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52bdb4f0",
      "metadata": {
        "id": "52bdb4f0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "178387b2",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "178387b2",
        "outputId": "51c690e1-8f9e-4e22-c2b1-cef32603ca60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Document Category\n",
              "0                     The sky is blue and beautiful.  weather\n",
              "1                  Love this blue and beautiful sky!  weather\n",
              "2       The quick brown fox jumps over the lazy dog.  animals\n",
              "3  A king's breakfast has sausages, ham, bacon, e...     food\n",
              "4        I love green eggs, ham, sausages and bacon!     food\n",
              "5   The brown fox is quick and the blue dog is lazy!  animals\n",
              "6  The sky is very blue and the sky is very beaut...  weather\n",
              "7        The dog is lazy but the brown fox is quick!  animals"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d50a9f62-39fa-42d3-acb1-8f9be705b5c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Document</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The sky is blue and beautiful.</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this blue and beautiful sky!</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The quick brown fox jumps over the lazy dog.</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A king's breakfast has sausages, ham, bacon, e...</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I love green eggs, ham, sausages and bacon!</td>\n",
              "      <td>food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The brown fox is quick and the blue dog is lazy!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The sky is very blue and the sky is very beaut...</td>\n",
              "      <td>weather</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The dog is lazy but the brown fox is quick!</td>\n",
              "      <td>animals</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d50a9f62-39fa-42d3-acb1-8f9be705b5c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d50a9f62-39fa-42d3-acb1-8f9be705b5c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d50a9f62-39fa-42d3-acb1-8f9be705b5c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "corpus = ['The sky is blue and beautiful.',\n",
        "          'Love this blue and beautiful sky!',\n",
        "          'The quick brown fox jumps over the lazy dog.',\n",
        "          \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans\",\n",
        "          'I love green eggs, ham, sausages and bacon!',\n",
        "          'The brown fox is quick and the blue dog is lazy!',\n",
        "          'The sky is very blue and the sky is very beautiful today',\n",
        "          'The dog is lazy but the brown fox is quick!'    \n",
        "]\n",
        "labels = ['weather', 'weather', 'animals', 'food', 'food', 'animals', 'weather', 'animals']\n",
        "\n",
        "corpus = np.array(corpus)\n",
        "corpus_df = pd.DataFrame({'Document': corpus, \n",
        "                          'Category': labels})\n",
        "corpus_df = corpus_df[['Document', 'Category']]\n",
        "corpus_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7Z-Ph-tWcB8",
        "outputId": "9aa43b7e-a41f-478b-fe5e-ff5112805100"
      },
      "id": "R7Z-Ph-tWcB8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOvnyx4QWmNA",
        "outputId": "873b4111-4cb3-4912-8a74-33f51cc8fff4"
      },
      "id": "DOvnyx4QWmNA",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c52258fc",
      "metadata": {
        "id": "c52258fc"
      },
      "outputs": [],
      "source": [
        "wpt = nltk.WordPunctTokenizer()\n",
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "def normalize_document(doc):\n",
        "    # lower case and remove special characters\\whitespaces\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    # tokenize document\n",
        "    tokens = wpt.tokenize(doc)\n",
        "    # filter stopwords out of document\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
        "    # re-create document from filtered tokens\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc\n",
        "\n",
        "normalize_corpus = np.vectorize(normalize_document)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b6f6458",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b6f6458",
        "outputId": "2129fc2d-9ddc-4cba-dde0-20d7c23beb85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sky blue beautiful', 'love blue beautiful sky',\n",
              "       'quick brown fox jumps lazy dog',\n",
              "       'kings breakfast sausages ham bacon eggs toast beans',\n",
              "       'love green eggs ham sausages bacon',\n",
              "       'brown fox quick blue dog lazy', 'sky blue sky beautiful today',\n",
              "       'dog lazy brown fox quick'], dtype='<U51')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "norm_corpus = normalize_corpus(corpus)\n",
        "norm_corpus"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb-xAawpWrru",
        "outputId": "0a2186e0-3825-4751-b25a-dd70ab109ddd"
      },
      "id": "xb-xAawpWrru",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ba8d95",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1ba8d95",
        "outputId": "c4765a08-fd35-4924-b9f0-24fb2246091e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total lines: 30103\n",
            "\n",
            "Sample line: ['1', ':', '6', 'And', 'God', 'said', ',', 'Let', 'there', 'be', 'a', 'firmament', 'in', 'the', 'midst', 'of', 'the', 'waters', ',', 'and', 'let', 'it', 'divide', 'the', 'waters', 'from', 'the', 'waters', '.']\n",
            "\n",
            "Processed line: god said let firmament midst waters let divide waters waters\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import gutenberg\n",
        "from string import punctuation\n",
        "\n",
        "bible = gutenberg.sents('bible-kjv.txt') \n",
        "remove_terms = punctuation + '0123456789'\n",
        "\n",
        "norm_bible = [[word.lower() for word in sent if word not in remove_terms] for sent in bible]\n",
        "norm_bible = [' '.join(tok_sent) for tok_sent in norm_bible]\n",
        "norm_bible = filter(None, normalize_corpus(norm_bible))\n",
        "norm_bible = [tok_sent for tok_sent in norm_bible if len(tok_sent.split()) > 2]\n",
        "\n",
        "print('Total lines:', len(bible))\n",
        "print('\\nSample line:', bible[10])\n",
        "print('\\nProcessed line:', norm_bible[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3cddf53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3cddf53",
        "outputId": "c31d172e-6abe-4c1c-a484-8aa5740b3e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 12425\n",
            "Vocabulary Sample: [('shall', 1), ('unto', 2), ('lord', 3), ('thou', 4), ('thy', 5), ('god', 6), ('ye', 7), ('said', 8), ('thee', 9), ('upon', 10)]\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import text\n",
        "\n",
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(norm_bible)\n",
        "\n",
        "word2id = tokenizer.word_index\n",
        "id2word = {v:k for k, v in word2id.items()}\n",
        "\n",
        "vocab_size = len(word2id) + 1 \n",
        "embed_size = 100\n",
        "\n",
        "wids = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in norm_bible]\n",
        "print('Vocabulary Size:', vocab_size)\n",
        "print('Vocabulary Sample:', list(word2id.items())[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db8c1c85",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db8c1c85",
        "outputId": "4bb72694-a74e-47ca-d1be-2baacd3ad2a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(james (1154), bible (5766)) -> 1\n",
            "(bible (5766), king (13)) -> 1\n",
            "(bible (5766), habitation (961)) -> 0\n",
            "(king (13), bible (5766)) -> 1\n",
            "(king (13), estimations (8757)) -> 0\n",
            "(james (1154), ashes (1224)) -> 0\n",
            "(james (1154), rivers (744)) -> 0\n",
            "(james (1154), king (13)) -> 1\n",
            "(king (13), tent (621)) -> 0\n",
            "(bible (5766), james (1154)) -> 1\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.sequence import skipgrams\n",
        "\n",
        "# generate skip-grams\n",
        "skip_grams = [skipgrams(wid, vocabulary_size=vocab_size, window_size=10) for wid in wids]\n",
        "\n",
        "# view sample skip-grams\n",
        "pairs, labels = skip_grams[0][0], skip_grams[0][1]\n",
        "for i in range(10):\n",
        "    print(\"({:s} ({:d}), {:s} ({:d})) -> {:d}\".format(\n",
        "          id2word[pairs[i][0]], pairs[i][0], \n",
        "          id2word[pairs[i][1]], pairs[i][1], \n",
        "          labels[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e24329f",
      "metadata": {
        "id": "8e24329f"
      },
      "outputs": [],
      "source": [
        "from keras.layers import concatenate\n",
        "from keras.layers.core import Dense, Reshape\n",
        "from keras.layers import Embedding\n",
        "from keras.models import Sequential\n",
        "\n",
        "# build skip-gram architecture\n",
        "word_model = Sequential()\n",
        "word_model.add(Embedding(vocab_size, embed_size,embeddings_initializer=\"glorot_uniform\",input_length=1))\n",
        "word_model.add(Reshape((embed_size, )))\n",
        "\n",
        "context_model = Sequential()\n",
        "context_model.add(Embedding(vocab_size, embed_size,embeddings_initializer=\"glorot_uniform\",input_length=1))\n",
        "context_model.add(Reshape((embed_size,)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46551169",
      "metadata": {
        "id": "46551169"
      },
      "outputs": [],
      "source": [
        "from keras.models import Model,Sequential \n",
        "from keras.layers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b4ef562",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b4ef562",
        "outputId": "7c9b7076-2336-4ea3-c671-2d1111f2fc76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " embedding_input (InputLayer)   [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding_1_input (InputLayer)  [(None, 1)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 100)       1242500     ['embedding_input[0][0]']        \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1, 100)       1242500     ['embedding_1_input[0][0]']      \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 100)          0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " reshape_1 (Reshape)            (None, 100)          0           ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 100)          0           ['reshape[0][0]',                \n",
            "                                                                  'reshape_1[0][0]']              \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)      (None, 1)            101         ['add[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,485,101\n",
            "Trainable params: 2,485,101\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "merged_output = add([word_model.output, context_model.output])  \n",
        "model_combined = Sequential()\n",
        "model_combined.add(Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\n",
        "final_model = Model([word_model.input, context_model.input], model_combined(merged_output))\n",
        "final_model.compile(loss=\"mean_squared_error\", optimizer=\"rmsprop\")\n",
        "final_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d869a0c6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d869a0c6",
        "outputId": "806f4e81-f1c7-45e6-fbbf-9ad8564ccac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Processed 10000 (skip_first, skip_second, relevance) pairs\n",
            "Processed 20000 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 1 Loss: 3649.2826708811335\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Processed 10000 (skip_first, skip_second, relevance) pairs\n",
            "Processed 20000 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 2 Loss: 3186.8045704226242\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Processed 10000 (skip_first, skip_second, relevance) pairs\n",
            "Processed 20000 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 3 Loss: 3126.018304068246\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Processed 10000 (skip_first, skip_second, relevance) pairs\n",
            "Processed 20000 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 4 Loss: 3094.31368598924\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Processed 10000 (skip_first, skip_second, relevance) pairs\n",
            "Processed 20000 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 5 Loss: 3079.254720001365\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, 6):\n",
        "    loss = 0\n",
        "    for i, elem in enumerate(skip_grams):\n",
        "        pair_first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
        "        pair_second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
        "        labels = np.array(elem[1], dtype='int32')\n",
        "        X = [pair_first_elem, pair_second_elem]\n",
        "        Y = labels\n",
        "        if i % 10000 == 0:\n",
        "            print('Processed {} (skip_first, skip_second, relevance) pairs'.format(i))\n",
        "        loss += final_model.train_on_batch(X,Y)  \n",
        "\n",
        "    print('Epoch:', epoch, 'Loss:', loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8210de38",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8210de38",
        "outputId": "42a73e3f-7d9c-458b-d477-dd880b2d1b75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12424, 12424)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'god': ['man', 'saying', 'thou', 'set', 'israel'],\n",
              " 'jesus': ['common', 'witnesses', 'wrong', 'harm', 'gift'],\n",
              " 'noah': ['bowl', 'hyssop', 'discomfited', 'wave', 'perizzites'],\n",
              " 'egypt': ['number', 'office', 'souls', 'law', 'remain'],\n",
              " 'john': ['devil', 'praying', 'forthwith', 'ravening', 'remission'],\n",
              " 'gospel': ['perfectly', 'stories', 'message', 'rust', 'unfruitful'],\n",
              " 'moses': ['avenge', 'afterward', 'read', 'prophets', 'intreat'],\n",
              " 'famine': ['balaam', 'likeness', 'eastward', 'heifer', 'token']}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "distance_matrix = euclidean_distances(weights)\n",
        "print(distance_matrix.shape)\n",
        "\n",
        "similar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]-1].argsort()[1:6]+1] \n",
        "                   for search_term in ['god', 'jesus', 'noah', 'egypt', 'john', 'gospel', 'moses','famine']}\n",
        "\n",
        "similar_words"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}